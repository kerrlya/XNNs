{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VR0wDf37QZYZ"
   },
   "source": [
    "# **RNN Classifier for Tweet Data**\n",
    "\n",
    "This notebook trains the model for an RNN classifier of our data. Word vectorization and recurrent neural network setup followed from youtube.\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "\n",
    "https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L15/1_lstm.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2GBA-LXTqDB"
   },
   "source": [
    "First install old version of torchtext because new ones have issues with legacy tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDsulUpWRlWH",
    "outputId": "b4ebcf2a-4e40-4213-858d-e4f626210cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (4.65.0)\n",
      "Requirement already satisfied: requests in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: torch in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: numpy in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (1.26.0)\n",
      "Requirement already satisfied: six in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torchtext==0.6.0) (0.1.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from requests->torchtext==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from requests->torchtext==0.6.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from requests->torchtext==0.6.0) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from torch->torchtext==0.6.0) (2023.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arjuntaneja/miniconda3/envs/XNNs/lib/python3.11/site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKOTkda4T5J4"
   },
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "id": "gCbYs3GrTxCI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXG5YqPAGOWE"
   },
   "source": [
    "Code for helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "id": "dRho-T0_GRFC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "    # Remove special characters, newlines, and punctuations\n",
    "    tweet = re.sub(r\"(@[A-Za-z0â€“9_]+)|[^\\w\\s]|#|http\\S+\", \"\", tweet)\n",
    "    # Remove extra whitespaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Kp3ZoF_wK1jA",
    "outputId": "f04d108e-3fb0-4e1a-cfea-155e02f95c70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'63millionbabies who have been killed by ROE RoeVWade SupremeCourt'"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet('#63millionbabies  who have been killed by ROE \\n#RoeVWade \\n#SupremeCourt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvdxN8P4UAGs"
   },
   "source": [
    "Settings for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "id": "FPeUlIEJT9n5"
   },
   "outputs": [],
   "source": [
    "##### select regularization type and strength\n",
    "L1_REG = False\n",
    "L1_PENALTY= 5e-6\n",
    "\n",
    "L2_REG = True\n",
    "L2_PENALTY = 8e-5\n",
    "\n",
    "# select cleaned or uncleaned\n",
    "IS_CLEAN = True\n",
    "\n",
    "# select data balancing choice (\"deletion\" or \"duplication\", otherwise, no balancing)\n",
    "BALANCE_CHOICE = \"deletion\"\n",
    "\n",
    "# select dropout rate\n",
    "DROPOUT_RATE = 0\n",
    "\n",
    "# number of layers\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "# Seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Vocabulary size\n",
    "VOCABULARY_SIZE = 3000\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2\n",
    "DATA_PATH = \"./tweets.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXDexYm4ULte"
   },
   "source": [
    "## Setup and Format Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVMahw_xxZJk"
   },
   "source": [
    "Balance data by either duplication or deletion (to prevent overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5rixSfgxfBl",
    "outputId": "fa05e535-e8ab-4d1f-dbdf-591c8dda6b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8816\n",
      "1    8816\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Count minority labels\n",
    "minority_label = label_counts.idxmin()\n",
    "minority_count = label_counts.min()\n",
    "\n",
    "if BALANCE_CHOICE == \"deletion\":\n",
    "  # Find indices of the majority class to delete excess samples\n",
    "  majority_indices = df[df['label'] != minority_label].index\n",
    "  excess_majority_indices = majority_indices[minority_count:]\n",
    "\n",
    "  # Delete excess samples from the majority class to balance the dataset\n",
    "  balanced_df = df.drop(excess_majority_indices)\n",
    "  balanced_df.to_csv(\"./tweetsDEL.csv\", index=False)\n",
    "  DATA_PATH = \"./tweetsDEL.csv\"\n",
    "elif BALANCE_CHOICE == \"duplication\":\n",
    "  # Find indices of the minority class to delete excess samples\n",
    "  minority_indices = df[df['label'] == minority_label].index\n",
    "\n",
    "  # duplicate samples from minority class\n",
    "  count_difference = abs(label_counts[0] - label_counts[1])\n",
    "  duplicate_indices = pd.Series(minority_indices).sample(n=count_difference, replace=True).values\n",
    "  duplicated_samples = df.loc[duplicate_indices]\n",
    "  balanced_df = df.append(duplicated_samples, ignore_index=True)\n",
    "\n",
    "  balanced_df.to_csv(\"./tweetsDUP.csv\", index=False)\n",
    "  DATA_PATH = \"./tweetsDUP.csv\"\n",
    "\n",
    "# Verify the new class distribution\n",
    "print(balanced_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT556hkVJMit"
   },
   "source": [
    "Additional cleaning to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "id": "rAn6JH1FJO8p"
   },
   "outputs": [],
   "source": [
    "if IS_CLEAN:\n",
    "  df = pd.read_csv(DATA_PATH)\n",
    "  df[\"text\"] = df[\"text\"].apply(clean_tweet)\n",
    "  df.to_csv(DATA_PATH, index=False) # don't write another df index column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnY04moYWE4X"
   },
   "source": [
    "Define text and label formatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "id": "7DAVzmWaVOPv"
   },
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dyUqipHWZz1"
   },
   "source": [
    "Process/format data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "id": "ncNIvzDEWYWZ"
   },
   "outputs": [],
   "source": [
    "fields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=DATA_PATH, format='csv',\n",
    "    skip_header=True, fields=fields)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdDi0VXiXfGG"
   },
   "source": [
    "## Split Dataset into Test/Train/Validation sets\n",
    "\n",
    "Test/Train split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "id": "8cxwbtuAXtiI"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = dataset.split(\n",
    "    split_ratio=[0.8, 0.2],\n",
    "    random_state=random.seed(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYZ2iR2bYEEh"
   },
   "source": [
    "Split train into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "id": "i9Z7GlQsXwhw"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(\n",
    "    split_ratio=[0.8, 0.20],\n",
    "    random_state=random.seed(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmYEEaXTYYki"
   },
   "source": [
    "Show sizes of sets and example text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVzh7GruYIfe",
    "outputId": "f35cd923-dce1-4820-a4c7-c86aed9d0519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size: 11285\n",
      "Train Size: 11285\n",
      "Validation Size: 2821\n",
      "{'text': ['63millionbabies', 'who', 'have', 'been', 'killed', 'by', 'ROE', 'RoeVWade', 'SupremeCourt'], 'label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Size: {len(train_data)}')\n",
    "print(f'Train Size: {len(train_data)}')\n",
    "print(f'Validation Size: {len(valid_data)}')\n",
    "print(vars(train_data.examples[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yoz-35XYe-l"
   },
   "source": [
    "## Build Vocabulary\n",
    "Valid words are the top frequent VOCABULARY_SIZE words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PEScKVYYyln",
    "outputId": "bb4e3252-be96-41ae-a968-f561bac75b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3002\n",
      "Label size: 2\n",
      "[('the', 12446), ('to', 11150), ('abortion', 7574), ('a', 6462), ('of', 6390), ('is', 6236), ('and', 6176), ('in', 4528), ('I', 4061), ('that', 3898), ('for', 3872), ('nt', 2937), ('you', 2908), ('are', 2865), ('Roe', 2521), ('have', 2459), ('not', 2385), ('be', 2282), ('it', 2230), ('on', 2218)]\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_data, max_size = 2)\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Label size: {len(LABEL.vocab)}')\n",
    "print(TEXT.vocab.freqs.most_common(20)) # most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRbTiIsRZhXZ",
    "outputId": "80f13a5f-5fa2-42c7-c581-095a11776ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 12446), ('to', 11150), ('abortion', 7574), ('a', 6462), ('of', 6390), ('is', 6236), ('and', 6176), ('in', 4528), ('I', 4061), ('that', 3898), ('for', 3872), ('nt', 2937), ('you', 2908), ('are', 2865), ('Roe', 2521), ('have', 2459), ('not', 2385), ('be', 2282), ('it', 2230), ('on', 2218)]\n",
      "['<unk>', '<pad>', 'the', 'to', 'abortion', 'a', 'of', 'is', 'and', 'in']\n",
      "2\n",
      "defaultdict(None, {'1': 0, '0': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'1': 5694, '0': 5591})"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print(TEXT.vocab.itos[:10])\n",
    "print(TEXT.vocab.stoi['the'])\n",
    "print(LABEL.vocab.stoi)\n",
    "LABEL.vocab.freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnvujU5yZ9uS"
   },
   "source": [
    "## Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "id": "aFjOWgWnaBSW"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = \\\n",
    "    torchtext.data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data),\n",
    "         batch_size=BATCH_SIZE,\n",
    "         sort_within_batch=False,\n",
    "         sort_key=lambda x: len(x.text),\n",
    "         device=DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_SUWBdzaBYj",
    "outputId": "25ed6e15-d892-4a22-e1c7-bc86fd7d0721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([56, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Valid:\n",
      "Text matrix size: torch.Size([8, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Test:\n",
      "Text matrix size: torch.Size([8, 128])\n",
      "Target vector size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.text.size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nValid:')\n",
    "for batch in valid_loader:\n",
    "    print(f'Text matrix size: {batch.text.size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break\n",
    "\n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.text.size()}')\n",
    "    print(f'Target vector size: {batch.label.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkIpjCZaafi3"
   },
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "id": "WthFTcb_aazO"
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        # self.rnn = torch.nn.RNN(embedding_dim,\n",
    "        #                        hidden_dim,\n",
    "        #                        nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, dropout=DROPOUT_RATE)\n",
    "        #self.rnn = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=NUM_LAYERS)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text dim: [sentence length, batch size]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "\n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "id": "RTCuyeZbadh8"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim=len(TEXT.vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # use weight decay for l2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD5YIU6zai-8"
   },
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwg5JLKYBDrQ"
   },
   "source": [
    "Function for L1 regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "id": "wY0hDXvKBDH3"
   },
   "outputs": [],
   "source": [
    "def l1_term(model, l1_penalty):\n",
    "  l1_loss = 0\n",
    "  for param in model.parameters():\n",
    "    l1_loss += torch.sum(torch.abs(param))\n",
    "  return l1_penalty * l1_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS-nzDZDDpZS"
   },
   "source": [
    "Function for L2 regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "id": "WOzJJwvRDrfa"
   },
   "outputs": [],
   "source": [
    "def l2_term(model, l2_penalty):\n",
    "    l2_loss = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_loss += torch.sum(param ** 2)\n",
    "    return 0.5 * l2_penalty * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "id": "8du5AFqHak0Y"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiWvVMODatCp",
    "outputId": "3fe98a15-e556-4019-b3dd-047d9ea690a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 000/089 | Loss: 16.1749\n",
      "Epoch: 001/015 | Batch 050/089 | Loss: 11.0299\n",
      "training accuracy: 50.73%\n",
      "valid accuracy: 50.80%\n",
      "Time elapsed: 0.20 min\n",
      "Epoch: 002/015 | Batch 000/089 | Loss: 8.2894\n",
      "Epoch: 002/015 | Batch 050/089 | Loss: 5.8429\n",
      "training accuracy: 49.57%\n",
      "valid accuracy: 49.77%\n",
      "Time elapsed: 0.39 min\n",
      "Epoch: 003/015 | Batch 000/089 | Loss: 4.5143\n",
      "Epoch: 003/015 | Batch 050/089 | Loss: 3.3088\n",
      "training accuracy: 50.73%\n",
      "valid accuracy: 50.37%\n",
      "Time elapsed: 0.57 min\n",
      "Epoch: 004/015 | Batch 000/089 | Loss: 2.6348\n",
      "Epoch: 004/015 | Batch 050/089 | Loss: 2.0254\n",
      "training accuracy: 49.58%\n",
      "valid accuracy: 49.56%\n",
      "Time elapsed: 0.76 min\n",
      "Epoch: 005/015 | Batch 000/089 | Loss: 1.6865\n",
      "Epoch: 005/015 | Batch 050/089 | Loss: 1.3742\n",
      "training accuracy: 50.71%\n",
      "valid accuracy: 50.09%\n",
      "Time elapsed: 0.93 min\n",
      "Epoch: 006/015 | Batch 000/089 | Loss: 1.1969\n",
      "Epoch: 006/015 | Batch 050/089 | Loss: 1.0418\n",
      "training accuracy: 54.53%\n",
      "valid accuracy: 49.63%\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 007/015 | Batch 000/089 | Loss: 0.9529\n",
      "Epoch: 007/015 | Batch 050/089 | Loss: 0.8745\n",
      "training accuracy: 51.08%\n",
      "valid accuracy: 49.20%\n",
      "Time elapsed: 1.27 min\n",
      "Epoch: 008/015 | Batch 000/089 | Loss: 0.8285\n",
      "Epoch: 008/015 | Batch 050/089 | Loss: 0.7844\n",
      "training accuracy: 49.54%\n",
      "valid accuracy: 49.63%\n",
      "Time elapsed: 1.43 min\n",
      "Epoch: 009/015 | Batch 000/089 | Loss: 0.7655\n",
      "Epoch: 009/015 | Batch 050/089 | Loss: 0.7410\n",
      "training accuracy: 50.73%\n",
      "valid accuracy: 50.41%\n",
      "Time elapsed: 1.60 min\n",
      "Epoch: 010/015 | Batch 000/089 | Loss: 0.7289\n",
      "Epoch: 010/015 | Batch 050/089 | Loss: 0.7223\n",
      "training accuracy: 50.73%\n",
      "valid accuracy: 50.05%\n",
      "Time elapsed: 1.78 min\n",
      "Epoch: 011/015 | Batch 000/089 | Loss: 0.7144\n",
      "Epoch: 011/015 | Batch 050/089 | Loss: 0.7082\n",
      "training accuracy: 51.40%\n",
      "valid accuracy: 49.59%\n",
      "Time elapsed: 1.96 min\n",
      "Epoch: 012/015 | Batch 000/089 | Loss: 0.7091\n",
      "Epoch: 012/015 | Batch 050/089 | Loss: 0.7022\n",
      "training accuracy: 50.74%\n",
      "valid accuracy: 50.34%\n",
      "Time elapsed: 2.14 min\n",
      "Epoch: 013/015 | Batch 000/089 | Loss: 0.6961\n",
      "Epoch: 013/015 | Batch 050/089 | Loss: 0.6976\n",
      "training accuracy: 50.99%\n",
      "valid accuracy: 49.59%\n",
      "Time elapsed: 2.32 min\n",
      "Epoch: 014/015 | Batch 000/089 | Loss: 0.7006\n",
      "Epoch: 014/015 | Batch 050/089 | Loss: 0.6632\n",
      "training accuracy: 76.36%\n",
      "valid accuracy: 72.70%\n",
      "Time elapsed: 2.49 min\n",
      "Epoch: 015/015 | Batch 000/089 | Loss: 0.5343\n",
      "Epoch: 015/015 | Batch 050/089 | Loss: 0.5928\n",
      "training accuracy: 82.41%\n",
      "valid accuracy: 77.74%\n",
      "Time elapsed: 2.66 min\n",
      "Total Training Time: 2.66 min\n",
      "Test accuracy: 75.44%\n",
      "Train accuracy: 82.38%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# early stopping \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "\n",
    "        text = batch_data.text.to(DEVICE)\n",
    "        labels = batch_data.label.to(DEVICE)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "\n",
    "        logits = model(text)\n",
    "\n",
    "        # regularization (optional)\n",
    "        loss = F.cross_entropy(logits, labels) # cross entropy loss tends to be better for classification problems\n",
    "\n",
    "        if L1_REG:\n",
    "          loss += l1_term(model, L1_PENALTY)\n",
    "\n",
    "        if L2_REG:\n",
    "          loss += l2_term(model, L2_PENALTY)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        # LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "\n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')\n",
    "print(f'Train accuracy: {compute_accuracy(model, train_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMdbrX2QbH1g"
   },
   "source": [
    "## Testing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test on basic examples with predict_side function (closer to 1 means pro-life, closer to 0 means pro-choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uc5HQPCwbDeI",
    "outputId": "d9414e6a-c02a-47f7-930a-f8af4d017c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score/Probability Pro-Life:\n",
      "women's rights are so important                                                       0.2429903745651245\n",
      "my body my choice, the government should keep their hands off women                   0.34514573216438293\n",
      "God loves babies thank god                                                            0.7602097988128662\n",
      "We have cats, cats are really cute and fuzzy                                          0.42585113644599915\n",
      "Potatoes                                                                              0.5442848205566406\n",
      "According to all known laws of aviation, a bee should not be able to fly.             0.4795265197753906\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def predict_side(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [token.text for token in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    return prediction[0][0].item()\n",
    "\n",
    "print('Score/Probability Pro-Life:')\n",
    "prompts = [\"women's rights are so important\", \n",
    "           \"my body my choice, the government should keep their hands off women\", \n",
    "           \"God loves babies thank god\",\n",
    "          \"We have cats, cats are really cute and fuzzy\",\n",
    "          \"Potatoes\", \n",
    "          \"According to all known laws of aviation, a bee should not be able to fly.\"]\n",
    "\n",
    "for prompt in prompts:\n",
    "    score = predict_side(model, prompt)\n",
    "    print(\"{:85} {}\".format(prompt, score))\n",
    "# print(f\"'women's rights are so important': {predict_side(model, \"womens rights are so important\")}\")\n",
    "# print(f\"{predict_side(model, \"my body my choice\")}\")\n",
    "# print(predict_side(model, \"God loves babies thank god \"))\n",
    "# print(predict_side(model, \"We have cats, cats are really cute and fuzzy\"))\n",
    "# print(predict_side(model, \"Potatoes\"))\n",
    "# print(predict_side(model, \"According to all known laws of aviation, a bee should not be able to fly.\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "id": "hDyXftyQrvPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt                                                                                Output\n",
      "God and the holy spirit love babies                                                   0.7531561255455017\n",
      "God and the holy spirit love babies cats                                              0.8430856466293335\n",
      "God and the holy spirit love babies cats cats                                         0.8669992685317993\n",
      "God and the holy spirit love babies cats cats cats                                    0.8663495779037476\n",
      "God and the holy spirit love babies cats cats cats cats                               0.8658765554428101\n",
      "God and the holy spirit love babies cats cats cats cats cats                          0.8655753135681152\n",
      "God and the holy spirit love babies cats cats cats cats cats cats                     0.865012526512146\n",
      "God and the holy spirit love babies cats cats cats cats cats cats cats                0.8644141554832458\n",
      "God and the holy spirit love babies cats cats cats cats cats cats cats cats           0.863788902759552\n",
      "God and the holy spirit love babies cats cats cats cats cats cats cats cats cats      0.8631443381309509\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), 'RNN_deletion.pth')\n",
    "print(\"{:85} {}\".format(\"Prompt\", \"Output\"))\n",
    "for cat_count in range(10):\n",
    "    prompt = f\"God and the holy spirit love babies \" + (\"cats \" * cat_count)\n",
    "    result = predict_side(model, prompt)\n",
    "    print(\"{:85} {}\".format(prompt, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_l2regularizaton.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello kerria\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
